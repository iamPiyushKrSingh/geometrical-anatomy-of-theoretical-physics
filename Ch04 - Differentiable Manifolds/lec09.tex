\lecture{9}

\section{Tangent Spaces to a Manifold}

Let \(M\) be a smooth manifold (from now on, whenever we say a smooth manifold, the associated topology and atlas are always implied). Then we can construct the following vector space over \(\R\):
\begin{equation}
	\qty(\SC^\infty(M), +, \cdot)
\end{equation}
where \(\SC^\infty(M) := \qty{f : M \to \R \mid f \text{ is smooth}}\) is the set of all smooth real-valued functions on \(M\). The notion of smoothness is via smooth charts in the atlas of \(M\). The addition and scalar multiplication are defined pointwise, for all \(f, g \in \SC^\infty(M)\), \(\lambda \in \R\), and \(p \in M\), as
\begin{align}
	(f + g)(p)           & := f(p) + g(p)         \\
	(\lambda \cdot f)(p) & := \lambda \cdot f(p).
\end{align}
It is easy to check that \(\qty(\SC^\infty(M), +, \cdot)\) is indeed a vector space over \(\R\).

\begin{definition}[Directional Derivative]
	Let \(\gamma: \R \to M\) be a smooth curve\footnotemark\ through a point \(p \in M\), and WLOG let \(\gamma(0) = p\). Then the \emph{directional derivative operator} along \(\gamma\) at \(p\) is a map
	\footnotetext{Here the notion of smoothness is via charts in the atlas of \(M\), \ie, for all charts \((U, x)\) of \(M\) such that \(p \in U\), the composition \(x \circ \gamma: \R \to \R^d\) is a smooth map in the usual sense.}
	\begin{equation}
		X_{\gamma, p} : \SC^\infty(M) \to \R
	\end{equation}
	defined as
	\begin{equation}
		\SC^\infty(M) \ni f \mapsto X_{\gamma, p}(f) := (f \circ \gamma)'(0) \in \R.
	\end{equation}
\end{definition}
Note the composition \(f \circ \gamma\) is a map from \(\R\) to \(\R\), and hence the derivative is the usual derivative of real-valued functions of a real variable.

\begin{proposition}
	The directional derivative operator \(X_{\gamma, p}\) along a smooth curve \(\gamma\) through \(p\) is a linear map, \ie, for all \(f, g \in \SC^\infty(M)\) and \(\lambda, \mu \in \R\),
	\begin{equation}
		X_{\gamma, p}(\lambda f + \mu g) = \lambda X_{\gamma, p}(f) + \mu X_{\gamma, p}(g).
	\end{equation}
\end{proposition}
\begin{proof}
	This follows from the linearity of the usual derivative of real-valued functions of a real variable.
	\begin{align*}
		X_{\gamma, p}(\lambda f + \mu g) & = ((\lambda f + \mu g) \circ \gamma)'(0)                  \\
		                                 & = (\lambda (f \circ \gamma) + \mu (g \circ \gamma))'(0)   \\
		                                 & = \lambda (f \circ \gamma)'(0) + \mu (g \circ \gamma)'(0) \\
		                                 & = \lambda X_{\gamma, p}(f) + \mu X_{\gamma, p}(g).
	\end{align*}
\end{proof}
In differential geometry, \(X_{\gamma, p}\) is usually called a \emph{tangent vector} to curve \(\gamma\) at point \(p\). Physically, we can think of \(X_{\gamma, p}\) as the velocity vector of a particle moving along the curve \(\gamma\) at point \(p\). To see this, let \(\gamma_1, \gamma_2: \R \to M\) be two smooth curves through \(p\) such that \(\gamma_1(0) = \gamma_2(0) = p\), and \(\gamma_1(t) = \gamma_2(2 t)\) for all \(t \in \R\). Let \(f \in \SC^\infty(M)\) be a smooth function. Then
\begin{equation}
	X_{\gamma_1, p}(f) = (f \circ \gamma_1)'(0) = (f \circ \gamma_2)'(0) \cdot 2 = 2 (f \circ \gamma_2)'(0) = 2 X_{\gamma_2, p}(f).
\end{equation}
This means that \(X_{\gamma_1, p} = 2 X_{\gamma_2, p}\). So, if we think of \(\gamma_1\) and \(\gamma_2\) as the trajectories of two particles moving through point \(p\) on manifold \(M\), then the velocity vector of the first particle at \(p\) is twice that of the second particle at \(p\), which is consistent with our physical intuition.

\begin{definition}[Tangent Vector Space]
	Let \(M\) be a smooth manifold and \(p \in M\). The \emph{tangent vector space} to \(M\) at \(p\), denoted by \(\ST_p M\), is defined as
	\begin{equation}
		\ST_p M := \qty{X_{\gamma, p} \mid \gamma: \R \to M \text{ is a smooth curve with } \gamma(0) = p}.
	\end{equation}
	Equipped with following operations:
	\begin{align*}
		 & \oplus: \ST_p M \times \ST_p M \to \ST_p M, \\
		 & \odot:  \R \times \ST_p M \to \ST_p M,
	\end{align*}
	defined pointwise as
	\begin{align*}
		(X_{\gamma_1, p} \oplus X_{\gamma_2, p})(f) & := X_{\gamma_1, p}(f) + X_{\gamma_2, p}(f), \quad \forall f \in \SC^\infty(M),                    \\
		(\lambda \odot X_{\gamma, p})(f)            & := \lambda \cdot X_{\gamma, p}(f), \quad \forall f \in \SC^\infty(M) \text{ and } \lambda \in \R,
	\end{align*}
	\(\qty(\ST_p M, \oplus, \odot)\) is a vector space over \(\R\).
\end{definition}
This definition is still incomplete, as the pointwise addition and scalar multiplication doesn't guarantee that the results are still in \(\ST_p M\). So, we have to prove the following proposition.
\begin{proposition}
	The operations \(\oplus\) and \(\odot\) defined above are closed in \(\ST_p M\), \ie, for all \(X_{\gamma_1, p}, X_{\gamma_2, p} \in \ST_p M\) and \(\lambda \in \R\),
	\begin{gather}
		X_{\gamma_1, p} \oplus X_{\gamma_2, p} \in \ST_p M, \\
		\lambda \odot X_{\gamma, p}            \in \ST_p M.
	\end{gather}
\end{proposition}
So we need to show that there exist smooth curves \(\gamma_3, \gamma_4: \R \to M\) such that \(\gamma_3(0) = \gamma_4(0) = p\) and
\begin{align*}
	X_{\gamma_3, p} & = X_{\gamma_1, p} \oplus X_{\gamma_2, p}, \\
	X_{\gamma_4, p} & = \lambda \odot X_{\gamma, p}.
\end{align*}
Since the notion of derivative is local, so if two curves agree on a neighborhood of \(0 \in \R\), then they have the same derivative at \(0\) \ie, if \(\gamma_1(t) = \gamma_2(t)\) for all \(t\) in some open interval containing \(0\), then \(X_{\gamma_1, p} = X_{\gamma_2, p}\). So, it is sufficient to construct \(\gamma_3\) and \(\gamma_4\) on some open interval containing \(0\).
\begin{proof}
	Let \((U, x)\) be a chart of \(M\) around \(p\), \ie, \(p \in U\) and \(x: U \to x(U) \subseteq \R^d\) is a homeomorphism.

	Let \(I \subseteq \R\) be an open interval containing \(0\) such that \(\gamma(t), \gamma_1(t), \gamma_2(t) \in U\) for all \(t \in I\). Such an interval exists since \(\gamma, \gamma_1, \gamma_2\) are continuous and \(\gamma(0) = \gamma_1(0) = \gamma_2(0) = p \in U\), and \(U\) is open in \(M\).
	\begin{enumerate}
		\item Construct a curve \(\gamma_3: I \to M\) using the chart \((U, x)\) as follows:
		      \begin{equation}
			      \gamma_3(t) := x^{-1} \circ (x \circ \gamma_1(t) + x \circ \gamma_2(t) - x(p)), \quad \forall t \in I.
		      \end{equation}
		      Note that \(x \circ \gamma_1(t), x \circ \gamma_2(t) \in \R^d\) and \(x(p) \in \R^d\), so the addition and subtraction are well-defined. Also, since \(x\) is a diffeomorphism, \(x \circ \gamma_1\) and \(x \circ \gamma_2\) are smooth maps from \(I\) to \(\R^d\), and hence their sum is also a smooth map from \(I\) to \(\R^d\). Therefore, the composition \(\gamma_3\) is a smooth map from \(I\) to \(M\). Moreover, \(\gamma_3(0) = x^{-1}(x(p) + x(p) - x(p)) = p\).

		      Now, for all \(f \in \SC^\infty(M)\),
		      \begin{align*}
			      X_{\gamma_3, p}(f) & = (f \circ \gamma_3)'(0)                                                                                                                  \\
			                         & = \qty(f \circ x^{-1} \circ (x \circ \gamma_1 + x \circ \gamma_2 - x(p)))'(0)                                                             \\
			      \intertext{map \(f \circ x^{-1}: x(U) \subseteq \R^d \to \R\), and \(x \circ \gamma_1 + x \circ \gamma_2 - x(p): I \subseteq \R \to \R^d\), so we can apply the multivariate chain rule, taking derivative in \(j\)-th coordinate direction, \(j = 1, \ldots, d\):}
			                         & = \qty[\partial_j (f \circ x^{-1})(x(p))] \cdot \qty(x^j \circ \gamma_1 + x^j \circ \gamma_2 - x^j(p))'(0)                                \\
			      \shortintertext{where \(x^j\) is the \(j\)-th coordinate function of chart \(x\). Here sum over \(j\) from \(1\) to \(d\) is implied. Using linearity of the usual derivative, we have:}
			                         & = \qty[\partial_j (f \circ x^{-1})(x(p))] \cdot \qty((x^j \circ \gamma_1)'(0) + (x^j \circ \gamma_2)'(0))                                 \\
			                         & = [\partial_j (f \circ x^{-1})(x(p)) \cdot (x^j \circ \gamma_1)'(0)] + [\partial_j (f \circ x^{-1})(x(p)) \cdot (x^j \circ \gamma_2)'(0)] \\
			      \shortintertext{combining the term in the square brackets, we get:}
			                         & = (f \circ \gamma_1)'(0) + (f \circ \gamma_2)'(0)                                                                                         \\
			                         & = X_{\gamma_1, p}(f) + X_{\gamma_2, p}(f)                                                                                                 \\
			                         & = (X_{\gamma_1, p} \oplus X_{\gamma_2, p})(f).
		      \end{align*}
		      Since this is true for all \(f \in \SC^\infty(M)\), we have
		      \begin{equation}
			      X_{\gamma_3, p} = X_{\gamma_1, p} \oplus X_{\gamma_2, p}.
		      \end{equation}

		\item Construct a curve \(\gamma_4: I \to M\) using the chart \((U, x)\) as follows:
		      \begin{equation}
			      \gamma_4(t) := x^{-1} \circ (x \circ \gamma(\lambda t)) , \quad \forall t \in I.
		      \end{equation}
		      Here it is tempting rewrite \(\gamma_4(t) = \gamma(\lambda t)\), but this lead to a problem that how to define \(f'(p)\) when we find \(X_{\gamma_4, p}(f)\).

		      Note that since \(x\) is a diffeomorphism, \(x \circ \gamma\) is a smooth map from \(I\) to \(\R^d\), and hence the composition \(\gamma_4\) is also a smooth map from \(I\) to \(M\). Moreover, \(\gamma_4(0) = x^{-1}(x(p)) = p\).

		      Now, for all \(f \in \SC^\infty(M)\),
		      \begin{align*}
			      X_{\gamma_4, p}(f) & = (f \circ \gamma_4)'(0)                                                                   \\
			                         & = \qty(f \circ x^{-1} \circ (x \circ \gamma(\lambda t)))'(0)                               \\
			      \intertext{map \(f \circ x^{-1}: x(U) \subseteq \R^d \to \R\), and \(x \circ \gamma(\lambda t): I \subseteq \R \to \R^d\), so we can apply the multivariate chain rule, taking derivative in \(j\)-th coordinate direction, \(j = 1, \ldots, d\):}
			                         & = \qty[\partial_j (f \circ x^{-1})(x(p))] \cdot \qty(x^j \circ \gamma(\lambda t))'(0)      \\
			      \shortintertext{where \(x^j\) is the \(j\)-th coordinate function of chart \(x\). Using the chain rule for the usual derivative, we have:}
			                         & = \qty[\partial_j (f \circ x^{-1})(x(p))] \cdot \qty[(x^j \circ \gamma)'(0) \cdot \lambda] \\
			                         & = \lambda [\partial_j (f \circ x^{-1})(x(p)) \cdot (x^j \circ \gamma)'(0)]                 \\
			      \shortintertext{combining the term in the square brackets, we get:}
			                         & = \lambda (f \circ \gamma)'(0)                                                             \\
			                         & = \lambda X_{\gamma, p}(f)                                                                 \\
			                         & = (\lambda \odot X_{\gamma, p})(f).
		      \end{align*}
		      Since this is true for all \(f \in \SC^\infty(M)\), we have
		      \begin{equation}
			      X_{\gamma_4, p} = \lambda \odot X_{\gamma, p}.
		      \end{equation}
	\end{enumerate}
\end{proof}
\begin{remark}[Independence of Chart Choice]
	The construction of \(\gamma_3\) and \(\gamma_4\) depends on the choice of chart \((U, x)\). However, the resulting tangent vectors \(X_{\gamma_3, p}\) and \(X_{\gamma_4, p}\) do not depend on the choice of chart. This is because if we choose another chart \((V, y)\) around \(p\), then the transition map \(y \circ x^{-1}: x(U \cap V) \to y(U \cap V)\) is a diffeomorphism between open subsets of \(\R^d\), and hence the construction of \(\gamma_3\) and \(\gamma_4\) using chart \((V, y)\) will yield the same tangent vectors \(X_{\gamma_3, p}\) and \(X_{\gamma_4, p}\).
\end{remark}

\subsection{Algebras and Derivations}

\begin{definition}[Algebra over a Field]
	Let \((V, +, \cdot)\) be a vector space over a field \(K\) equipped with a ``product'' operation,
	\begin{equation}
		\bullet: V \times V \to V,
	\end{equation}
	such that \(\bullet\) is bilinear. Then \((V, +, \cdot, \bullet)\) is called an \emph{algebra over field \(K\)}.
\end{definition}
In the future, we will impose more conditions on the product operation \(\bullet\), such as anti-symmetry to get something called a Lie algebra. A typical example for that is the cross product in \(\R^3\).
\begin{example}[Algebra of Smooth Functions]
	We have already seen that \(\qty(\SC^\infty(M), +, \cdot)\) is a vector space over \(\R\). Now, we can define a product operation \(\bullet\) on \(\SC^\infty(M)\) as follows:
	\begin{equation}
		\begin{aligned}
			\bullet: \SC^\infty(M) \times \SC^\infty(M) & \to \SC^\infty(M),  \\
			(f, g)                                      & \mapsto f \bullet g
		\end{aligned}
	\end{equation}
	where \((f \bullet g)(p) := f(p) \cdot g(p)\) for all \(p \in M\). It is easy to check that \(\bullet\) is bilinear, and hence \(\qty(\SC^\infty(M), +, \cdot, \bullet)\) is an algebra over \(\R\).

	Note the difference between \(\cdot\) and \(\bullet\): the former is scalar multiplication, while the latter is function multiplication, both at heart uses the field multiplication in \(\R\).
\end{example}
Let's look at some special algebras where the product operation satisfies some special properties.
\begin{definition}
	Let \((V, +, \cdot, \bullet)\) be an algebra over a field \(K\). The algebra is called:
	\begin{itemize}
		\item \emph{Associative} if for all \(u, v, w \in V\),
		      \begin{equation}
			      (u \bullet v) \bullet w = u \bullet (v \bullet w).
		      \end{equation}
		\item \emph{Commutative} if for all \(u, v \in V\),
		      \begin{equation}
			      u \bullet v = v \bullet u.
		      \end{equation}
		\item \emph{Unital} if there exists an element \(\mathbf{1} \in V\) such that
		      \begin{equation}
			      \mathbf{1} \bullet v = v \bullet \mathbf{1} = v, \quad \forall v \in V.
		      \end{equation}
	\end{itemize}
\end{definition}
Now let's look at more important class of algebras, which are not necessarily associative or commutative.
\begin{definition}[Lie Algebra]
	A \emph{Lie algebra} over a field \(K\) is an algebra \((V, +, \cdot, \comm{\star}{\star})\) such that the product operation \(\comm{\star}{\star}\), called the \emph{Lie bracket}, satisfies the following properties:
	\begin{itemize}
		\item \emph{Antisymmetry}: for all \(u, v \in V\),
		      \begin{equation}
			      \comm{u}{v} = -\comm{v}{u}.
		      \end{equation}
		\item \emph{Jacobi Identity}: for all \(u, v, w \in V\),
		      \begin{equation}
			      \comm{u}{\comm{v}{w}} + \comm{v}{\comm{w}{u}} + \comm{w}{\comm{u}{v}} = 0.
		      \end{equation}
	\end{itemize}
	Note that the \(0\) here is the additive identity of the vector space \((V, +, \cdot)\).
\end{definition}
It is easy to see that for a non-trivial Lie bracket, the algebra cannot be unital.

\begin{definition}[Derivation]
	Let \((V, +, \cdot, \bullet)\) be an algebra over a field \(K\). A \emph{derivation} on \(V\) is a linear map \(D: V \to V\) such that it satisfies the Leibniz rule:
	\begin{equation}
		D(u \bullet v) = D(u) \bullet v + u \bullet D(v), \quad \forall u, v \in V.
	\end{equation}
\end{definition}
\begin{example}[Derivation on Smooth Functions]
	We have already seen that \((\SC^\infty(M), +, \cdot, \bullet)\) is an algebra over \(\R\). Fix a point \(p \in M\), take any tangent vector \(X_{\gamma, p} \in \ST_p M\). We know from the definition that \(X_{\gamma, p}: \SC^\infty(M) \to \R\) is a linear map. Now let's check if it satisfies the Leibniz rule, for all \(f, g \in \SC^\infty(M)\),
	\begin{align*}
		X_{\gamma, p}(f \bullet g) & = ((f \bullet g) \circ \gamma)'(0)                                                                \\
		                           & = ((f \circ \gamma) \cdot (g \circ \gamma))'(0)                                                   \\
		                           & = (f \circ \gamma)'(0) \cdot (g \circ \gamma)(0) + (f \circ \gamma)(0) \cdot (g \circ \gamma)'(0) \\
		                           & = X_{\gamma, p}(f) \cdot g(p) + f(p) \cdot X_{\gamma, p}(g).
	\end{align*}
	So, \(X_{\gamma, p}\) satisfies the Leibniz rule. However, note that \(X_{\gamma, p}(f)\) is a real number, not a smooth function on \(M\). So, \(X_{\gamma, p}\) is not a derivation on the algebra \((\SC^\infty(M), +, \cdot, \bullet)\), usually called a derivation at point \(p\).

	Now define a map
	\begin{equation}
		\begin{aligned}
			D: \SC^\infty(M) & \to \SC^\infty(M), \\
			f                & \mapsto D(f)
		\end{aligned}
	\end{equation}
	where \(D(f)(p) := X_{\gamma, p}(f)\) for all \(p \in M\). Then \(D\) is a derivation on the algebra \((\SC^\infty(M), +, \cdot, \bullet)\).
\end{example}

\begin{example}
	Let \(V\) be the vector space over \(\R\), define \(A := \End(V)\), we know that \((A, +, \cdot)\) is a vector space over \(\R\). Now define a product operation on \(A\) as follows:
	\begin{equation}
		\begin{aligned}
			\comm{\star}{\star}: A \times A & \to A,                                                          \\
			(\phi, \psi)                    & \mapsto \comm{\phi}{\psi} := \phi \circ \psi - \psi \circ \phi,
		\end{aligned}
	\end{equation}
	where \(\circ\) is the composition of linear maps. It is easy to see that \(\comm{\star}{\star}\) is bilinear, and hence \((A, +, \cdot, \comm{\star}{\star})\) is an algebra over \(\R\).
	Moreover, \(\comm{\star}{\star}\) is antisymmetric, and for all \(\phi, \psi, \rho \in A\),
	\begin{equation}
		\comm{\phi}{\comm{\psi}{\rho}} + \comm{\psi}{\comm{\rho}{\phi}} + \comm{\rho}{\comm{\phi}{\psi}} = 0,
	\end{equation}
	which is called the \emph{Jacobi identity}. So, \((A, +, \cdot, \comm{\star}{\star})\) is a Lie algebra over \(\R\).

	Now fix \(H \in A\), define a map
	\begin{equation}
		\begin{aligned}
			D_H : A & \to A,                               \\
			\phi    & \mapsto D_H(\phi) := \comm{H}{\phi}.
		\end{aligned}
	\end{equation}
	Let's check if \(D_H\) is a derivation, for all \(\phi, \psi \in A\),
	\begin{align*}
		D_H(\comm{\phi}{\psi}) & = \comm{H}{\comm{\phi}{\psi}}                                \\
		\shortintertext{using the Jacobi identity, we have:}
		                       & = -\comm{\phi}{\comm{\psi}{H}} - \comm{\psi}{\comm{H}{\phi}} \\
		\shortintertext{rearranging the terms and use antisymmetry, we get:}
		                       & = \comm{\comm{H}{\phi}}{\psi} + \comm{\phi}{\comm{H}{\psi}}  \\
		                       & = \comm{D_H(\phi)}{\psi} + \comm{\phi}{D_H(\psi)}.
	\end{align*}
	So, \(D_H\) is a derivation on the Lie algebra \((A, +, \cdot, \comm{\star}{\star})\).
\end{example}
With this example, we can see the algebraic structure of Poisson brackets in classical mechanics, and the commutator in quantum mechanics.
\begin{remark}[Poisson Bracket]
	In classical mechanics, the state of a system is represented by a point in phase space (which is a symplectic manifold), and observables are represented by smooth functions on the phase space. The Poisson bracket defines a Lie algebra structure on the space of observables. If we fix an observable \(H\) (the Hamiltonian), then the map \(D_H(f) := \acomm{H}{f}\) is a derivation on the Lie algebra of observables, which generates the time evolution of the system according to Hamilton's equations.
\end{remark}
\begin{remark}[Commutator in Quantum Mechanics]
	Similarly, in quantum mechanics, the state of a system is represented by a vector in a Hilbert space, and observables are represented by self-adjoint operators on that space. The commutator defines a Lie algebra structure on the space of observables. If we fix an observable \(H\) (the Hamiltonian operator), then the map \(D_H(\phi) := \comm{H}{\phi}\) is a derivation on the Lie algebra of observables, which generates the time evolution of the system according to the Heisenberg equation of motion.
\end{remark}

\subsection{Basis and Dimension of Tangent Space}

We have shown that for a smooth manifold \(M\) and a point \(p \in M\), the set of tangent vectors \(\ST_p M\) is a vector space over \(\R\). Now we will prove a very crucial theorem in differential geometry, which states that the dimension of the tangent space \(\ST_p M\) is equal to the dimension of the manifold \(M\).

\begin{theorem}[Dimension of Tangent Space]
	Let \(M\) be a smooth manifold of dimension \(d\), then for all \(p \in M\), the tangent vector space \(\ST_p M\) is a vector space over \(\R\) of dimension \(d\).
	\begin{equation}
		\dim(\ST_p M) = \dim(M) = d.
	\end{equation}
\end{theorem}
Note that we have used the same symbol \(\dim\) for the dimension of a manifold and the dimension of a vector space, but they are different concepts. The dimension of a manifold is defined as the dimension of the Euclidean space that it locally resembles, while the dimension of a vector space is defined as the cardinality of its basis.
\begin{proof}
	Fix a point \(p \in M\), and fix a chart \((U, x)\) of \(M\) around \(p\).

	To prove this theorem, we will construct a basis of \(\ST_p M\) consisting of \(d\) tangent vectors.

	Define \(d\) curves \(\gamma_j: \R \to U\), \(j = 1, \ldots, d\), such that
	\begin{equation}
		\gamma_j(0) = p; \qquad \qquad \qquad \qquad x^i \circ \gamma_j(t) = \delta_j^i t, \quad \forall t \in \R,
	\end{equation}
	where \(x^i\) is the \(i\)-th coordinate function of chart \(x\), and \(\delta_j^i\) is the Kronecker delta. So pictorially, \(\gamma_j\) is a curve that moves along the \(j\)-th coordinate axis in the Euclidean space \(\R^d\) under the chart \(x\).

	Name the corresponding tangent vectors at \(p\) as
	\begin{equation}
		\vb{e}_j := X_{\gamma_j, p}, \quad j = 1, \ldots, d.
	\end{equation}
	Let's look at how \(\vb{e}_j\) acts on a smooth function \(f \in \SC^\infty(M)\):
	\begin{align*}
		\vb{e}_j(f) & = (f \circ \gamma_j)'(0) = \qty(f \circ \id_U \circ \gamma_j)'(0)            \\
		\shortintertext{insert the identity map \(\id_U = x^{-1} \circ x\) on \(U\):}
		            & = \qty(f \circ x^{-1} \circ (x \circ \gamma_j))'(0)                          \\
		            & = \qty[\partial_i (f \circ x^{-1})(x(p))] \cdot \qty(x^i \circ \gamma_j)'(0) \\
		            & = \qty[\partial_i (f \circ x^{-1})(x(p))] \cdot \delta_j^i                   \\
		            & = \partial_j (f \circ x^{-1})(x(p)).
	\end{align*}
	Define a formal symbol as
	\begin{equation}
		\qty(\pdv{x^j})_p (f) := \partial_j (f \circ x^{-1})(x(p)), \quad \forall f \in \SC^\infty(M).
	\end{equation}
	Don't confuse this notation with the usual partial derivative of a function of several real variables.
	\begin{align*}
		 & \qty(\partial_j)_p: \SC^\infty(\R^d, \R) \to \R, \\
		 & \qty(\pdv{x^j})_p: \SC^\infty(M) \to \R.
	\end{align*}
	So we have
	\begin{equation}
		\vb{e}_j = \qty(\pdv{x^j})_p, \quad j = 1, \ldots, d.
	\end{equation}
	Define the set
	\begin{equation}
		\SB := \qty{\vb{e}_1, \ldots, \vb{e}_d} = \qty{\qty(\pdv{x^1})_p, \ldots, \qty(\pdv{x^d})_p}.
	\end{equation}
	We will show that \(\SB\) is a basis of \(\ST_p M\), \ie, for any \(X \in \ST_p M\), there exist unique real numbers \(X^1, \ldots, X^d\) such that
	\begin{equation}
		X = X^j \vb{e}_j = X^j \qty(\pdv{x^j})_p. \qquad \text{(sum over \(j\) from \(1\) to \(d\) is implied)}
	\end{equation}
	\begin{enumerate}
		\item \textbf{Spanning}: We know \(\exists \gamma: \R \to M\) such that \(X = X_{\gamma, p}\). For all \(f \in \SC^\infty(M)\),
		      \begin{align*}
			      X(f) & = (f \circ \gamma)'(0) = \qty(f \circ \id_U \circ \gamma)'(0)              \\
			      \shortintertext{insert the identity map \(\id_U = x^{-1} \circ x\) on \(U\):}
			           & = \qty(f \circ x^{-1} \circ (x \circ \gamma))'(0)                          \\
			           & = \qty[\partial_i (f \circ x^{-1})(x(p))] \cdot \qty(x^i \circ \gamma)'(0) \\
			           & = (x^i \circ \gamma)'(0) \cdot \qty(\pdv{x^i})_p (f).
		      \end{align*}
		      Note that \(x^i \circ \gamma: \R \to \R\) is a smooth function of a real variable, so \((x^i \circ \gamma)'(0) \in \R\). Define
		      \begin{equation}
			      X^i := (x^i \circ \gamma)'(0) \in \R, \quad i = 1, \ldots, d.
		      \end{equation}
		      So we have
		      \begin{equation}
			      X(f) = X^i \qty(\pdv{x^i})_p (f) = X^i \vb{e}_i(f), \quad \forall f \in \SC^\infty(M).
		      \end{equation}
		      Since this is true for all \(f \in \SC^\infty(M)\), we have
		      \begin{equation}
			      X = X^i \vb{e}_i.
		      \end{equation}
		      Thus, \(\ST_p M = \Span(\SB)\).

		      \begin{remark}[Smoothness of Chart map and co-ordinate functions]
			      In general to talk about smooth of any function \(f: M \to \R\), we have used charts such that \(f\) is smooth if and only if \(f \circ x^{-1}: x(U) \subseteq \R^d \to \R\).

			      So by this definition, the chart map \(x: U \to x(U) \subseteq \R^d\) is trivially smooth, since \(x \circ x^{-1} = \id_{x(U)}\) is smooth. Similarly, the coordinate functions \(x^i: U \to \R\) are also smooth, since \(x^i \circ x^{-1}: x(U) \subseteq \R^d \to \R\) is just the projection onto the \(i\)-th coordinate, which is a linear map and hence smooth.
		      \end{remark}

		\item \textbf{Linear Independence}: Suppose that \(\SB\) is linearly dependent, then there exist real numbers \(X^1, \ldots, X^d\), not all zero, such that
		      \begin{equation}
			      X^j \vb{e}_j = 0.
		      \end{equation}
		      So for all \(f \in \SC^\infty(M)\), we have \(X^j \vb{e}_j(f) = 0\). In particular, take \(f = x^i\), the \(i\)-th coordinate function of chart \(x\), then
		      \begin{align*}
			      0 & = X^j \vb{e}_j(x^i) = X^j \qty(\pdv{x^j})_p (x^i) = X^j \partial_j (x^i \circ x^{-1})(x(p)) \\
			        & = X^j \partial_j (\proj^i) (x(p)) = X^j \delta_j^i = X^i.
		      \end{align*}
		      Since this is true for all \(i = 1, \ldots, d\), we have \(X^1 = X^2 = \ldots = X^d = 0\), which contradicts our assumption. Hence, \(\SB\) is linearly independent.
	\end{enumerate}
	Therefore, \(\SB\) is a basis of \(\ST_p M\), and \(\dim(\ST_p M) = d\).
\end{proof}
Terminology: Let \(X \in \ST_p M\), then we have
\begin{equation}
	X = X^j \qty(\pdv{x^j})_p,
\end{equation}
where \(X^j = X(x^j) = (x^j \circ \gamma)'(0)\) are called the \emph{components} of \(X\) with respect to the basis \(\SB\) induced by the chart \((U, x)\).

\subsection{Change of Basis and Coordinate Transformation}

In the construction of the basis \(\SB\) of \(\ST_p M\), we have used a chart \((U, x)\) around \(p\). Now suppose we have another chart \((V', y)\) around \(p\), we can similarly construct another basis of \(\ST_p M\) as
\begin{equation}
	\tilde{\SB} := \qty{\tilde{\vb{e}}_1, \ldots, \tilde{\vb{e}}_d} = \qty{\qty(\pdv{y^1})_p, \ldots, \qty(\pdv{y^d})_p}.
\end{equation}
For simiplicity, define \(V := U \cap V'\), which is also a chart neighborhood of \(p\), now we have two charts \((V, x)\) and \((V, y)\) around \(p\).

These two charts induce two different bases \(\SB\) and \(\tilde{\SB}\) of the same vector space \(\ST_p M\), so there must exist a change of basis map between them \(A, B \in \End(\ST_p M)\) such that
\begin{align} \label{eq:change-of-basis-tangent-space}
	\tilde{\vb{e}}_j & = \tensor{A}{^i_j} \vb{e}_i, & \vb{e}_j & = \tensor{B}{^i_j} \tilde{\vb{e}}_i,
\end{align}
where \(\tensor{A}{^i_j}, \tensor{B}{^i_j} \in \R\) are the components of the linear maps \(A\) and \(B\) with respect to the basis \(\SB\). Since change of basis maps are invertible, we have the following relation
\begin{equation}
	\tensor{A}{^i_j} \tensor{B}{^k_i} = \tensor{\delta}{^k_j} = \tensor{B}{^i_j} \tensor{A}{^k_i}.
\end{equation}
Now let's find the explicit form of the components \(\tensor{A}{^i_j}\) and \(\tensor{B}{^i_j}\). Take \(x^k\), the \(k\)-th coordinate function of chart \(x\), and apply \(\tilde{\vb{e}}_j\) on it, we have
\begin{align*}
	\tilde{\vb{e}}_j(x^k)               & = \tensor{A}{^i_j} \vb{e}_i(x^k)                       \\
	\qty(\pdv{y^j})_p (x^k)             & = \tensor{A}{^i_j} \qty(\pdv{x^i})_p (x^k)             \\
	\partial_j (x^k \circ y^{-1})(y(p)) & = \tensor{A}{^i_j} \partial_i (x^k \circ x^{-1})(x(p)) \\
	\partial_j (x^k \circ y^{-1})(y(p)) & = \tensor{A}{^i_j} \delta_i^k                          \\
	\partial_j (x^k \circ y^{-1})(y(p)) & = \tensor{A}{^k_j}.
\end{align*}
So we have
\begin{equation}
	\tensor{A}{^k_j} = \partial_j (x^k \circ y^{-1})(y(p)).
\end{equation}
Similarly, take \(y^k\), the \(k\)-th coordinate function of chart \(y\), and apply \(\vb{e}_j\) on it, we have
\begin{equation}
	\tensor{B}{^k_j} = \partial_j (y^k \circ x^{-1})(x(p)).
\end{equation}
With this let's look at the transformation of components of a tangent vector \(X \in \ST_p M\) under change of basis. We have
\begin{equation}
	X = X^j \vb{e}_j = \tilde{X}^j \tilde{\vb{e}}_j,
\end{equation}
where \(X^j = X(x^j)\) and \(\tilde{X}^j = X(y^j)\) are the components of \(X\) with respect to the bases \(\SB\) and \(\tilde{\SB}\) respectively. Using the change of basis relation \eqref{eq:change-of-basis-tangent-space}, we have
\begin{equation*}
	X = X^j \vb{e}_j = X^j \tensor{B}{^i_j} \tilde{\vb{e}}_i = \tilde{X}^i \tilde{\vb{e}}_i.
\end{equation*}
Since \(\tilde{\SB}\) is a basis, we have
\begin{equation}
	\tilde{X}^i = X^j \tensor{B}{^i_j} = X^j \partial_j (y^i \circ x^{-1})(x(p)).
\end{equation}

Now, let's write this component of change of basis in a more familiar form, \ie, the Jacobian matrix of the coordinate transformation. Note that the transition map between the two charts \((V, x)\) and \((V, y)\) is given by
\begin{equation}
	y^i \circ x^{-1}: x(V) \subseteq \R^d \to \R.
\end{equation}
Abusing the notation a bit, for now call \(y^i \circ x^{-1}\) as \(y^i\), so \(y^i\) is a real-valued smooth function of \(d\) real variables. Since we are only interested in a single point \(p \in V\), we can think of \(x^j\) as independent variables for the function \(y^i\). So we have
\begin{equation}
	y^i = y^i(x^1, \ldots, x^d).
\end{equation}
With this new interpretation, we have
\begin{equation}
	\partial_j (y^i \circ x^{-1})(x(p)) = \pdv{y^i}{x^j} \qty(x(p)).
\end{equation}
Similarly, we can also write
\begin{equation}
	\partial_j (x^i \circ y^{-1})(y(p)) = \pdv{x^i}{y^j} \qty(y(p)).
\end{equation}
So the change of basis relation \eqref{eq:change-of-basis-tangent-space} can be rewritten as
\begin{align}
	\tilde{\vb{e}}_j & = \pdv{y^i}{x^j} \qty(x(p)) \vb{e}_i, & \vb{e}_j & = \pdv{x^i}{y^j} \qty(y(p)) \tilde{\vb{e}}_i,
\end{align}
and the transformation of components of a tangent vector \(X \in \ST_p M\) under change of basis can be rewritten as
\begin{equation} \label{eq:transformation-of-components-tangent-vector}
	\tilde{X}^i = X^j \pdv{y^i}{x^j} \qty(x(p)).
\end{equation}
\begin{remark}[Jacobian Matrix]
	Let \(f: \R^m \to \R^n\) be a smooth map, then the Jacobian matrix of \(f\) at a point \(a \in \R^m\) is defined as the \(n \times m\) matrix whose \((i, j)\)-th entry is given by
	\begin{equation}
		\pdv{f^i}{x^j} \qty(a),
	\end{equation}
	where \(f^i\) is the \(i\)-th component function of \(f\), and \(x^j\) is the \(j\)-th coordinate of \(\R^m\).
\end{remark}

In older literature, you may see that the transformation law (see \eqref{eq:transformation-of-components-tangent-vector}) is being used to define a `vector'. It goes like this: an array of \(d\) real numbers \((X^1, \ldots, X^d)\) is called a vector if under a change of coordinates \(x \to y = y(x)\), the components transform as
\begin{equation}
	\tilde{X}^i = X^j \pdv{y^i}{x^j}.
\end{equation}
This definition is not wrong, but it is not very useful, since it does not tell you what a vector actually is.

\subsubsection{Position Vector in Physics}

In physics, we often talk about the position vector of a point in space. From all this discussion, only coordinate functions \(x^i\) looks like a good candidate for a position vector. However, this does not make sense, as we have seen that vectors have a specific transformation law under change of coordinates. Let's consider a chart \((U, y)\) such that \(y\) is highly non-linear, for example, polar coordinates in \(\R^2\). So the transformation of components of \(y^i\) under change of basis will not be linear, and hence \(y^i\) cannot be a vector.

This shows that the concept of position vector in physics is not very well-defined in the context of differential geometry. In fact, the position vector is not a vector in the sense of differential geometry, but rather an image of a point on a manifold under a chart map.
